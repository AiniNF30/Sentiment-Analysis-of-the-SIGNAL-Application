{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of the Signal app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Sastrawi in /opt/anaconda3/envs/sentimen-analisis/lib/python3.9/site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Sastrawi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/aininurpadilah/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aininurpadilah/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "import csv\n",
    "import requests\n",
    "from io import StringIO\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4fafbc04-ea97-455e-a287-33b937b31c3b</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Tampilan aplikasi sudah bagus dan enak dipanda...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1.5.12</td>\n",
       "      <td>2025-01-28 09:15:05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7fc0d4c4-eb64-4475-b67e-91431fa9ad3d</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Dulu mantap. Sekarang sampah. Maaf ya min. Mau...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1.5.12</td>\n",
       "      <td>2025-02-02 15:47:59</td>\n",
       "      <td>Hai kak, terima kasih atas ulasannya. Terus gu...</td>\n",
       "      <td>2022-04-18 16:38:53</td>\n",
       "      <td>1.5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f5d168c3-84e8-456c-b042-30aad0d1b0ee</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Tidak ada opsi utk memilih pembayaran dgn bank...</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>1.5.12</td>\n",
       "      <td>2025-01-11 15:53:53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cfb09d3b-67ea-4072-a5bb-43e60203f2e2</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Mau TAMBAH kendaraan aja ga bisa terus muncul ...</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1.5.12</td>\n",
       "      <td>2025-01-17 07:20:51</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bc5b9102-b2b5-4125-a762-e7349dcb2e1a</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>ketika harus ada maintenace atau gangguan haru...</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1.5.12</td>\n",
       "      <td>2025-01-16 12:13:59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.5.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId         userName  \\\n",
       "0  4fafbc04-ea97-455e-a287-33b937b31c3b  Pengguna Google   \n",
       "1  7fc0d4c4-eb64-4475-b67e-91431fa9ad3d  Pengguna Google   \n",
       "2  f5d168c3-84e8-456c-b042-30aad0d1b0ee  Pengguna Google   \n",
       "3  cfb09d3b-67ea-4072-a5bb-43e60203f2e2  Pengguna Google   \n",
       "4  bc5b9102-b2b5-4125-a762-e7349dcb2e1a  Pengguna Google   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  Tampilan aplikasi sudah bagus dan enak dipanda...      2             15   \n",
       "1  Dulu mantap. Sekarang sampah. Maaf ya min. Mau...      1             37   \n",
       "2  Tidak ada opsi utk memilih pembayaran dgn bank...      3             20   \n",
       "3  Mau TAMBAH kendaraan aja ga bisa terus muncul ...      1             34   \n",
       "4  ketika harus ada maintenace atau gangguan haru...      1             14   \n",
       "\n",
       "  reviewCreatedVersion                   at  \\\n",
       "0               1.5.12  2025-01-28 09:15:05   \n",
       "1               1.5.12  2025-02-02 15:47:59   \n",
       "2               1.5.12  2025-01-11 15:53:53   \n",
       "3               1.5.12  2025-01-17 07:20:51   \n",
       "4               1.5.12  2025-01-16 12:13:59   \n",
       "\n",
       "                                        replyContent            repliedAt  \\\n",
       "0                                                NaN                  NaN   \n",
       "1  Hai kak, terima kasih atas ulasannya. Terus gu...  2022-04-18 16:38:53   \n",
       "2                                                NaN                  NaN   \n",
       "3                                                NaN                  NaN   \n",
       "4                                                NaN                  NaN   \n",
       "\n",
       "  appVersion  \n",
       "0     1.5.12  \n",
       "1     1.5.12  \n",
       "2     1.5.12  \n",
       "3     1.5.12  \n",
       "4     1.5.12  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "app_reviews_df = pd.read_csv('reviews_signal.csv')\n",
    "app_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48794 entries, 0 to 48793\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reviewId              48794 non-null  object\n",
      " 1   userName              48794 non-null  object\n",
      " 2   userImage             48794 non-null  object\n",
      " 3   content               48794 non-null  object\n",
      " 4   score                 48794 non-null  int64 \n",
      " 5   thumbsUpCount         48794 non-null  int64 \n",
      " 6   reviewCreatedVersion  43729 non-null  object\n",
      " 7   at                    48794 non-null  object\n",
      " 8   replyContent          10645 non-null  object\n",
      " 9   repliedAt             10645 non-null  object\n",
      " 10  appVersion            43729 non-null  object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# dataset information\n",
    "app_reviews_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9750 entries, 1 to 47821\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reviewId              9750 non-null   object\n",
      " 1   userName              9750 non-null   object\n",
      " 2   userImage             9750 non-null   object\n",
      " 3   content               9750 non-null   object\n",
      " 4   score                 9750 non-null   int64 \n",
      " 5   thumbsUpCount         9750 non-null   int64 \n",
      " 6   reviewCreatedVersion  9750 non-null   object\n",
      " 7   at                    9750 non-null   object\n",
      " 8   replyContent          9750 non-null   object\n",
      " 9   repliedAt             9750 non-null   object\n",
      " 10  appVersion            9750 non-null   object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 914.1+ KB\n"
     ]
    }
   ],
   "source": [
    "# clean dataset\n",
    "clean_df = app_reviews_df.dropna()\n",
    "clean_df = clean_df.drop_duplicates()\n",
    "clean_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocess Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # menghapus mention\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # menghapus hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # menghapus RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # menghapus link\n",
    "    text = re.sub(r'[0-9]+', '', text) # menghapus angka\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # menghapus karakter selain huruf dan angka\n",
    "\n",
    "    text = text.replace('\\n', ' ') # mengganti baris baru dengan spasi\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # menghapus semua tanda baca\n",
    "    text = text.strip(' ') # menghapus karakter spasi dari kiri dan kanan teks\n",
    "    return text\n",
    "\n",
    "def casefoldingText(text): # Mengubah semua karakter dalam teks menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "def tokenizingText(text): # Memecah atau membagi string, teks menjadi daftar token\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    "\n",
    "def filteringText(text): # Menghapus stopwords dalam teks\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    listStopwords1 = set(stopwords.words('english'))\n",
    "    listStopwords.update(listStopwords1)\n",
    "    listStopwords.update([listStopwords.update(['aplikasi', 'aja', 'dong', 'tolong', 'nih', 'kayak', 'bisa', 'ga', 'gak', 'nya', 'deh', 'dong', 'min', 'sih', 'kan', 'loh', 'yah', 'ya'])\n",
    "    ])\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "    return text\n",
    "\n",
    "def stemmingText(text): # Mengurangi kata ke bentuk dasarnya yang menghilangkan imbuhan awalan dan akhiran atau ke akar kata\n",
    "    # Membuat objek stemmer\n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "\n",
    "    # Memecah teks menjadi daftar kata\n",
    "    words = text.split()\n",
    "\n",
    "    # Menerapkan stemming pada setiap kata dalam daftar\n",
    "    stemmed_words = [stemmer.stem(word) for word in words]\n",
    "\n",
    "    # Menggabungkan kata-kata yang telah distem\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "\n",
    "    return stemmed_text\n",
    "\n",
    "def toSentence(list_words): # Mengubah daftar kata menjadi kalimat\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indonesian Slangwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "slangwords = {\n",
    "    \"@\": \"di\",\n",
    "    \"abis\": \"habis\",\n",
    "    \"wtb\": \"beli\",\n",
    "    \"masi\": \"masih\",\n",
    "    \"wts\": \"jual\",\n",
    "    \"wtt\": \"tukar\",\n",
    "    \"bgt\": \"banget\",\n",
    "    \"maks\": \"maksimal\",\n",
    "    \"sampe\": \"sampai\",\n",
    "    \"tdk\": \"tidak\",\n",
    "    \"krn\": \"karena\",\n",
    "    \"dgn\": \"dengan\",\n",
    "    \"sblm\": \"sebelum\",\n",
    "    \"udh\": \"sudah\",\n",
    "    \"blm\": \"belum\",\n",
    "    \"trs\": \"terus\",\n",
    "    \"lg\": \"lagi\",\n",
    "    \"gpp\": \"tidak apa-apa\",\n",
    "    \"tp\": \"tapi\",\n",
    "    \"msh\": \"masih\",\n",
    "    \"kyk\": \"kayak\",\n",
    "    \"jg\": \"juga\",\n",
    "    \"dr\": \"dari\",\n",
    "    \"sm\": \"sama\",\n",
    "    \"qta\": \"kita\",\n",
    "    \"gak\": \"tidak\",\n",
    "    \"ga\": \"tidak\",\n",
    "    \"bsk\": \"besok\",\n",
    "    \"kpn\": \"kapan\",\n",
    "    \"kmrn\": \"kemarin\",\n",
    "    \"td\": \"tadi\",\n",
    "    \"sy\": \"saya\",\n",
    "    \"gw\": \"saya\",\n",
    "    \"gue\": \"saya\",\n",
    "    \"loe\": \"kamu\",\n",
    "    \"lu\": \"kamu\",\n",
    "    \"knp\": \"kenapa\",\n",
    "    \"brb\": \"sebentar\",\n",
    "    \"btw\": \"ngomong-ngomong\",\n",
    "    \"dmn\": \"dimana\",\n",
    "    \"mlm\": \"malam\",\n",
    "    \"pg\": \"pagi\",\n",
    "    \"cm\": \"cuma\"\n",
    "}\n",
    "def fix_slangwords(text):\n",
    "    words = text.split()\n",
    "    fixed_words = []\n",
    "\n",
    "    for word in words:\n",
    "        if word.lower() in slangwords:\n",
    "            fixed_words.append(slangwords[word.lower()])\n",
    "        else:\n",
    "            fixed_words.append(word)\n",
    "\n",
    "    fixed_text = ' '.join(fixed_words)\n",
    "    return fixed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7fc0d4c4-eb64-4475-b67e-91431fa9ad3d</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Dulu mantap. Sekarang sampah. Maaf ya min. Mau...</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1.5.12</td>\n",
       "      <td>2025-02-02 15:47:59</td>\n",
       "      <td>Hai kak, terima kasih atas ulasannya. Terus gu...</td>\n",
       "      <td>2022-04-18 16:38:53</td>\n",
       "      <td>1.5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5bf20a77-7c33-464b-ad95-6214b0c01eac</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>asli dan semua jadi lebih mudah.. tinggal dudu...</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1.5.12</td>\n",
       "      <td>2025-01-07 11:42:54</td>\n",
       "      <td>Hai kak, terima kasih atas ulasannya. Terus gu...</td>\n",
       "      <td>2023-01-16 09:05:24</td>\n",
       "      <td>1.5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>9409d8cd-49be-4cfc-8d98-9acb896aeb49</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>aplikasi yang sangat susah dalam proses pendaf...</td>\n",
       "      <td>4</td>\n",
       "      <td>46</td>\n",
       "      <td>1.5.12</td>\n",
       "      <td>2025-01-14 11:57:57</td>\n",
       "      <td>Hai, kami mohon maaf atas ketidaknyamanannya. ...</td>\n",
       "      <td>2022-08-08 13:43:46</td>\n",
       "      <td>1.5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>4f688ed7-1d25-4363-bc92-8b5e524bd13d</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Kenapa aplikasi signal dari tgl 5 sampe tangga...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5.12</td>\n",
       "      <td>2025-01-09 18:24:05</td>\n",
       "      <td>Hai kak, terima kasih atas respon positifnya. ...</td>\n",
       "      <td>2024-01-18 15:07:26</td>\n",
       "      <td>1.5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>bb193c27-3235-48e1-a47e-98957264ae15</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Dulu bisa dan lancar, tetapi setelah ganti kal...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.5.12</td>\n",
       "      <td>2025-02-05 13:26:52</td>\n",
       "      <td>Hai kak, terima kasih atas ulasannya. Terus gu...</td>\n",
       "      <td>2023-01-06 15:12:49</td>\n",
       "      <td>1.5.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47816</th>\n",
       "      <td>d5f5db72-7949-490b-92b6-3be713f58c1e</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Mantap</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2.4</td>\n",
       "      <td>2021-07-31 07:29:14</td>\n",
       "      <td>Hai, terima kasih atas ulasannya :) Terus guna...</td>\n",
       "      <td>2021-08-03 17:41:35</td>\n",
       "      <td>1.2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47817</th>\n",
       "      <td>3c2adf77-77a1-46ff-8ad0-039c06d9955e</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Bagus</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2.4</td>\n",
       "      <td>2021-08-09 08:58:18</td>\n",
       "      <td>Hai Febri, terima kasih atas ulasannya :) Teru...</td>\n",
       "      <td>2021-08-10 18:03:05</td>\n",
       "      <td>1.2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47818</th>\n",
       "      <td>a544355d-7028-42e8-b1ce-f7fc391124f7</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Bermanfaat</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2.4</td>\n",
       "      <td>2021-08-05 19:24:13</td>\n",
       "      <td>Hai, terima kasih atas ulasannya :) Terus guna...</td>\n",
       "      <td>2021-08-04 18:46:49</td>\n",
       "      <td>1.2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47820</th>\n",
       "      <td>c860e4e0-496b-434e-ad2b-ee722c55bc1a</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>ngemudahin banget</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2.4</td>\n",
       "      <td>2021-08-26 15:09:25</td>\n",
       "      <td>Hai, terima kasih atas ulasannya :) Terus guna...</td>\n",
       "      <td>2021-08-27 10:55:46</td>\n",
       "      <td>1.2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47821</th>\n",
       "      <td>3997d6ae-4175-4236-81b4-871721d6dc55</td>\n",
       "      <td>Pengguna Google</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Ok seep</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2.4</td>\n",
       "      <td>2021-08-11 09:49:31</td>\n",
       "      <td>Hai Jaya, terima kasih atas ulasannya :) Terus...</td>\n",
       "      <td>2021-08-13 17:58:54</td>\n",
       "      <td>1.2.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9750 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   reviewId         userName  \\\n",
       "1      7fc0d4c4-eb64-4475-b67e-91431fa9ad3d  Pengguna Google   \n",
       "6      5bf20a77-7c33-464b-ad95-6214b0c01eac  Pengguna Google   \n",
       "136    9409d8cd-49be-4cfc-8d98-9acb896aeb49  Pengguna Google   \n",
       "207    4f688ed7-1d25-4363-bc92-8b5e524bd13d  Pengguna Google   \n",
       "462    bb193c27-3235-48e1-a47e-98957264ae15  Pengguna Google   \n",
       "...                                     ...              ...   \n",
       "47816  d5f5db72-7949-490b-92b6-3be713f58c1e  Pengguna Google   \n",
       "47817  3c2adf77-77a1-46ff-8ad0-039c06d9955e  Pengguna Google   \n",
       "47818  a544355d-7028-42e8-b1ce-f7fc391124f7  Pengguna Google   \n",
       "47820  c860e4e0-496b-434e-ad2b-ee722c55bc1a  Pengguna Google   \n",
       "47821  3997d6ae-4175-4236-81b4-871721d6dc55  Pengguna Google   \n",
       "\n",
       "                                               userImage  \\\n",
       "1      https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "6      https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "136    https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "207    https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "462    https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "...                                                  ...   \n",
       "47816  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "47817  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "47818  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "47820  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "47821  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                                 content  score  \\\n",
       "1      Dulu mantap. Sekarang sampah. Maaf ya min. Mau...      1   \n",
       "6      asli dan semua jadi lebih mudah.. tinggal dudu...      2   \n",
       "136    aplikasi yang sangat susah dalam proses pendaf...      4   \n",
       "207    Kenapa aplikasi signal dari tgl 5 sampe tangga...      5   \n",
       "462    Dulu bisa dan lancar, tetapi setelah ganti kal...      2   \n",
       "...                                                  ...    ...   \n",
       "47816                                             Mantap      5   \n",
       "47817                                              Bagus      5   \n",
       "47818                                         Bermanfaat      5   \n",
       "47820                                  ngemudahin banget      5   \n",
       "47821                                            Ok seep      5   \n",
       "\n",
       "       thumbsUpCount reviewCreatedVersion                   at  \\\n",
       "1                 37               1.5.12  2025-02-02 15:47:59   \n",
       "6                 58               1.5.12  2025-01-07 11:42:54   \n",
       "136               46               1.5.12  2025-01-14 11:57:57   \n",
       "207                0               1.5.12  2025-01-09 18:24:05   \n",
       "462                0               1.5.12  2025-02-05 13:26:52   \n",
       "...              ...                  ...                  ...   \n",
       "47816              0                1.2.4  2021-07-31 07:29:14   \n",
       "47817              0                1.2.4  2021-08-09 08:58:18   \n",
       "47818              0                1.2.4  2021-08-05 19:24:13   \n",
       "47820              0                1.2.4  2021-08-26 15:09:25   \n",
       "47821              0                1.2.4  2021-08-11 09:49:31   \n",
       "\n",
       "                                            replyContent            repliedAt  \\\n",
       "1      Hai kak, terima kasih atas ulasannya. Terus gu...  2022-04-18 16:38:53   \n",
       "6      Hai kak, terima kasih atas ulasannya. Terus gu...  2023-01-16 09:05:24   \n",
       "136    Hai, kami mohon maaf atas ketidaknyamanannya. ...  2022-08-08 13:43:46   \n",
       "207    Hai kak, terima kasih atas respon positifnya. ...  2024-01-18 15:07:26   \n",
       "462    Hai kak, terima kasih atas ulasannya. Terus gu...  2023-01-06 15:12:49   \n",
       "...                                                  ...                  ...   \n",
       "47816  Hai, terima kasih atas ulasannya :) Terus guna...  2021-08-03 17:41:35   \n",
       "47817  Hai Febri, terima kasih atas ulasannya :) Teru...  2021-08-10 18:03:05   \n",
       "47818  Hai, terima kasih atas ulasannya :) Terus guna...  2021-08-04 18:46:49   \n",
       "47820  Hai, terima kasih atas ulasannya :) Terus guna...  2021-08-27 10:55:46   \n",
       "47821  Hai Jaya, terima kasih atas ulasannya :) Terus...  2021-08-13 17:58:54   \n",
       "\n",
       "      appVersion  \n",
       "1         1.5.12  \n",
       "6         1.5.12  \n",
       "136       1.5.12  \n",
       "207       1.5.12  \n",
       "462       1.5.12  \n",
       "...          ...  \n",
       "47816      1.2.4  \n",
       "47817      1.2.4  \n",
       "47818      1.2.4  \n",
       "47820      1.2.4  \n",
       "47821      1.2.4  \n",
       "\n",
       "[9750 rows x 11 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### text preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membersihkan teks dan menyimpannya di kolom 'text_clean'\n",
    "clean_df['text_clean'] = clean_df['content'].apply(cleaningText)\n",
    "\n",
    "# Mengubah huruf dalam teks menjadi huruf kecil dan menyimpannya di 'text_casefoldingText'\n",
    "clean_df['text_casefoldingText'] = clean_df['text_clean'].apply(casefoldingText)\n",
    "\n",
    "# Mengganti kata-kata slang dengan kata-kata standar dan menyimpannya di 'text_slangwords'\n",
    "clean_df['text_slangwords'] = clean_df['text_casefoldingText'].apply(fix_slangwords)\n",
    "\n",
    "# Memecah teks menjadi token (kata-kata) dan menyimpannya di 'text_tokenizingText'\n",
    "clean_df['text_tokenizingText'] = clean_df['text_slangwords'].apply(tokenizingText)\n",
    "\n",
    "# Menghapus kata-kata stop (kata-kata umum) dan menyimpannya di 'text_stopword'\n",
    "clean_df['text_stopword'] = clean_df['text_tokenizingText'].apply(filteringText)\n",
    "\n",
    "# Menggabungkan token-token menjadi kalimat dan menyimpannya di 'text_akhir'\n",
    "clean_df['text_akhir'] = clean_df['text_stopword'].apply(toSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch Positive and Negative Words Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_positive = dict()\n",
    "\n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_positive.csv')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "    for row in reader:\n",
    "        lexicon_positive[row[0]] = int(row[1])\n",
    "else:\n",
    "    print(\"Failed to fetch positive lexicon data\")\n",
    "\n",
    "lexicon_negative = dict()\n",
    "\n",
    "response = requests.get('https://raw.githubusercontent.com/angelmetanosaa/dataset/main/lexicon_negative.csv')\n",
    "\n",
    "if response.status_code == 200:\n",
    "    reader = csv.reader(StringIO(response.text), delimiter=',')\n",
    "    for row in reader:\n",
    "        lexicon_negative[row[0]] = int(row[1])\n",
    "else:\n",
    "    print(\"Failed to fetch negative lexicon data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(text):\n",
    "    score = 0\n",
    "\n",
    "    for word in text:\n",
    "        if word in lexicon_positive:\n",
    "            score += lexicon_positive[word]\n",
    "\n",
    "    for word in text:\n",
    "        if word in lexicon_negative:\n",
    "            score += lexicon_negative[word]\n",
    "\n",
    "    if score > 0:\n",
    "        polarity = 'positive'\n",
    "    elif score < 0:\n",
    "        polarity = 'negative'\n",
    "    else:\n",
    "        polarity = 'neutral'\n",
    "\n",
    "    return score, polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform data labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity\n",
      "positive    4349\n",
      "negative    3806\n",
      "neutral     1595\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "results = clean_df['text_stopword'].apply(sentiment_analysis)\n",
    "results = list(zip(*results))\n",
    "clean_df['polarity_score'] = results[0]\n",
    "clean_df['polarity'] = results[1]\n",
    "print(clean_df['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "polarity\n",
      "positive    4349\n",
      "negative    3806\n",
      "neutral     1595\n",
      "Name: count, dtype: int64\n",
      "polarity\n",
      "positive    4349\n",
      "negative    4349\n",
      "neutral     4349\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(clean_df['polarity'].value_counts())\n",
    "\n",
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = clean_df[clean_df['polarity'] == 'positive']\n",
    "df_minority_neg = clean_df[clean_df['polarity'] == 'negative']\n",
    "df_minority_neu = clean_df[clean_df['polarity'] == 'neutral']\n",
    "\n",
    "df_minority_neg_upsampled = resample(df_minority_neg,\n",
    "                                     replace=True,\n",
    "                                     n_samples=len(df_majority),\n",
    "                                     random_state=42)\n",
    "\n",
    "df_minority_neu_upsampled = resample(df_minority_neu,\n",
    "                                     replace=True,\n",
    "                                     n_samples=len(df_majority),\n",
    "                                     random_state=42)\n",
    "\n",
    "clean_df = pd.concat([df_majority, df_minority_neg_upsampled, df_minority_neu_upsampled])\n",
    "print(clean_df['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction: TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aamiin</th>\n",
       "      <th>acc</th>\n",
       "      <th>account</th>\n",
       "      <th>ad</th>\n",
       "      <th>adakah</th>\n",
       "      <th>adany</th>\n",
       "      <th>admin</th>\n",
       "      <th>admin rp</th>\n",
       "      <th>admin signal</th>\n",
       "      <th>administrasi</th>\n",
       "      <th>...</th>\n",
       "      <th>yg terimapadahal</th>\n",
       "      <th>yg terimapadahal pake</th>\n",
       "      <th>yg terkait</th>\n",
       "      <th>yg udah</th>\n",
       "      <th>yg urus</th>\n",
       "      <th>yg yg</th>\n",
       "      <th>yng</th>\n",
       "      <th>youtube</th>\n",
       "      <th>zaman</th>\n",
       "      <th>zonk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13042</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13043</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13044</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13045</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13046</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13047 rows × 5000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aamiin  acc  account   ad  adakah  adany  admin  admin rp  \\\n",
       "0         0.0  0.0      0.0  0.0     0.0    0.0    0.0       0.0   \n",
       "1         0.0  0.0      0.0  0.0     0.0    0.0    0.0       0.0   \n",
       "2         0.0  0.0      0.0  0.0     0.0    0.0    0.0       0.0   \n",
       "3         0.0  0.0      0.0  0.0     0.0    0.0    0.0       0.0   \n",
       "4         0.0  0.0      0.0  0.0     0.0    0.0    0.0       0.0   \n",
       "...       ...  ...      ...  ...     ...    ...    ...       ...   \n",
       "13042     0.0  0.0      0.0  0.0     0.0    0.0    0.0       0.0   \n",
       "13043     0.0  0.0      0.0  0.0     0.0    0.0    0.0       0.0   \n",
       "13044     0.0  0.0      0.0  0.0     0.0    0.0    0.0       0.0   \n",
       "13045     0.0  0.0      0.0  0.0     0.0    0.0    0.0       0.0   \n",
       "13046     0.0  0.0      0.0  0.0     0.0    0.0    0.0       0.0   \n",
       "\n",
       "       admin signal  administrasi  ...  yg terimapadahal  \\\n",
       "0               0.0           0.0  ...               0.0   \n",
       "1               0.0           0.0  ...               0.0   \n",
       "2               0.0           0.0  ...               0.0   \n",
       "3               0.0           0.0  ...               0.0   \n",
       "4               0.0           0.0  ...               0.0   \n",
       "...             ...           ...  ...               ...   \n",
       "13042           0.0           0.0  ...               0.0   \n",
       "13043           0.0           0.0  ...               0.0   \n",
       "13044           0.0           0.0  ...               0.0   \n",
       "13045           0.0           0.0  ...               0.0   \n",
       "13046           0.0           0.0  ...               0.0   \n",
       "\n",
       "       yg terimapadahal pake  yg terkait  yg udah  yg urus  yg yg  yng  \\\n",
       "0                        0.0         0.0      0.0      0.0    0.0  0.0   \n",
       "1                        0.0         0.0      0.0      0.0    0.0  0.0   \n",
       "2                        0.0         0.0      0.0      0.0    0.0  0.0   \n",
       "3                        0.0         0.0      0.0      0.0    0.0  0.0   \n",
       "4                        0.0         0.0      0.0      0.0    0.0  0.0   \n",
       "...                      ...         ...      ...      ...    ...  ...   \n",
       "13042                    0.0         0.0      0.0      0.0    0.0  0.0   \n",
       "13043                    0.0         0.0      0.0      0.0    0.0  0.0   \n",
       "13044                    0.0         0.0      0.0      0.0    0.0  0.0   \n",
       "13045                    0.0         0.0      0.0      0.0    0.0  0.0   \n",
       "13046                    0.0         0.0      0.0      0.0    0.0  0.0   \n",
       "\n",
       "       youtube  zaman  zonk  \n",
       "0          0.0    0.0   0.0  \n",
       "1          0.0    0.0   0.0  \n",
       "2          0.0    0.0   0.0  \n",
       "3          0.0    0.0   0.0  \n",
       "4          0.0    0.0   0.0  \n",
       "...        ...    ...   ...  \n",
       "13042      0.0    0.0   0.0  \n",
       "13043      0.0    0.0   0.0  \n",
       "13044      0.0    0.0   0.0  \n",
       "13045      0.0    0.0   0.0  \n",
       "13046      0.0    0.0   0.0  \n",
       "\n",
       "[13047 rows x 5000 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = clean_df['text_akhir']\n",
    "y = clean_df['polarity']\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=5000, min_df=5, max_df=0.8, ngram_range=(1,3))\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "tfidf_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "tfidf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction: Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.332504</td>\n",
       "      <td>0.172245</td>\n",
       "      <td>-0.116238</td>\n",
       "      <td>0.094762</td>\n",
       "      <td>-0.049907</td>\n",
       "      <td>-0.788415</td>\n",
       "      <td>0.094166</td>\n",
       "      <td>0.636442</td>\n",
       "      <td>-0.264668</td>\n",
       "      <td>-0.075670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386844</td>\n",
       "      <td>0.352235</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.145713</td>\n",
       "      <td>0.755200</td>\n",
       "      <td>0.211378</td>\n",
       "      <td>0.181323</td>\n",
       "      <td>-0.343293</td>\n",
       "      <td>-0.139336</td>\n",
       "      <td>-0.316692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.589436</td>\n",
       "      <td>0.263487</td>\n",
       "      <td>-0.232126</td>\n",
       "      <td>0.173135</td>\n",
       "      <td>-0.038550</td>\n",
       "      <td>-1.217594</td>\n",
       "      <td>0.178163</td>\n",
       "      <td>0.976128</td>\n",
       "      <td>-0.433724</td>\n",
       "      <td>-0.089417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.555034</td>\n",
       "      <td>0.582209</td>\n",
       "      <td>0.080897</td>\n",
       "      <td>0.221712</td>\n",
       "      <td>1.192142</td>\n",
       "      <td>0.329190</td>\n",
       "      <td>0.339222</td>\n",
       "      <td>-0.478558</td>\n",
       "      <td>-0.244708</td>\n",
       "      <td>-0.572417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.345709</td>\n",
       "      <td>0.153301</td>\n",
       "      <td>-0.141187</td>\n",
       "      <td>0.119342</td>\n",
       "      <td>-0.083962</td>\n",
       "      <td>-0.749887</td>\n",
       "      <td>0.090132</td>\n",
       "      <td>0.594755</td>\n",
       "      <td>-0.260055</td>\n",
       "      <td>-0.034043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.347890</td>\n",
       "      <td>0.355982</td>\n",
       "      <td>0.014971</td>\n",
       "      <td>0.158488</td>\n",
       "      <td>0.716392</td>\n",
       "      <td>0.183754</td>\n",
       "      <td>0.217741</td>\n",
       "      <td>-0.293098</td>\n",
       "      <td>-0.167957</td>\n",
       "      <td>-0.323338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.432365</td>\n",
       "      <td>0.194523</td>\n",
       "      <td>-0.215070</td>\n",
       "      <td>0.132175</td>\n",
       "      <td>-0.079571</td>\n",
       "      <td>-0.929174</td>\n",
       "      <td>0.111993</td>\n",
       "      <td>0.738147</td>\n",
       "      <td>-0.323012</td>\n",
       "      <td>-0.022582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390612</td>\n",
       "      <td>0.463735</td>\n",
       "      <td>0.034536</td>\n",
       "      <td>0.160252</td>\n",
       "      <td>0.880091</td>\n",
       "      <td>0.239239</td>\n",
       "      <td>0.249958</td>\n",
       "      <td>-0.348369</td>\n",
       "      <td>-0.183390</td>\n",
       "      <td>-0.427813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.279774</td>\n",
       "      <td>0.139654</td>\n",
       "      <td>-0.120850</td>\n",
       "      <td>0.089880</td>\n",
       "      <td>-0.102853</td>\n",
       "      <td>-0.678232</td>\n",
       "      <td>0.051077</td>\n",
       "      <td>0.522569</td>\n",
       "      <td>-0.222429</td>\n",
       "      <td>-0.037328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.314768</td>\n",
       "      <td>0.314552</td>\n",
       "      <td>0.003595</td>\n",
       "      <td>0.139178</td>\n",
       "      <td>0.617549</td>\n",
       "      <td>0.164465</td>\n",
       "      <td>0.165511</td>\n",
       "      <td>-0.268333</td>\n",
       "      <td>-0.132418</td>\n",
       "      <td>-0.258280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13042</th>\n",
       "      <td>-0.006089</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.008655</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>-0.008338</td>\n",
       "      <td>-0.007564</td>\n",
       "      <td>-0.002700</td>\n",
       "      <td>-0.000516</td>\n",
       "      <td>-0.008517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>-0.004861</td>\n",
       "      <td>0.008112</td>\n",
       "      <td>0.009054</td>\n",
       "      <td>-0.008368</td>\n",
       "      <td>-0.002677</td>\n",
       "      <td>-0.008360</td>\n",
       "      <td>-0.008883</td>\n",
       "      <td>-0.008379</td>\n",
       "      <td>-0.001913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13043</th>\n",
       "      <td>-0.523359</td>\n",
       "      <td>0.305356</td>\n",
       "      <td>-0.149150</td>\n",
       "      <td>0.089477</td>\n",
       "      <td>0.042632</td>\n",
       "      <td>-1.293895</td>\n",
       "      <td>0.192093</td>\n",
       "      <td>1.063071</td>\n",
       "      <td>-0.363038</td>\n",
       "      <td>-0.233954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.607264</td>\n",
       "      <td>0.589680</td>\n",
       "      <td>0.125108</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>1.162051</td>\n",
       "      <td>0.376272</td>\n",
       "      <td>0.150795</td>\n",
       "      <td>-0.588625</td>\n",
       "      <td>-0.130647</td>\n",
       "      <td>-0.488587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13044</th>\n",
       "      <td>-0.689724</td>\n",
       "      <td>0.270339</td>\n",
       "      <td>-0.320044</td>\n",
       "      <td>0.261136</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>-1.259431</td>\n",
       "      <td>0.216002</td>\n",
       "      <td>1.008751</td>\n",
       "      <td>-0.477269</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484293</td>\n",
       "      <td>0.657897</td>\n",
       "      <td>0.106884</td>\n",
       "      <td>0.249119</td>\n",
       "      <td>1.301834</td>\n",
       "      <td>0.359773</td>\n",
       "      <td>0.435488</td>\n",
       "      <td>-0.426840</td>\n",
       "      <td>-0.326925</td>\n",
       "      <td>-0.675156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13045</th>\n",
       "      <td>0.007902</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>-0.001760</td>\n",
       "      <td>0.008787</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>-0.007556</td>\n",
       "      <td>0.006201</td>\n",
       "      <td>-0.008532</td>\n",
       "      <td>-0.004208</td>\n",
       "      <td>0.001095</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008522</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>-0.000901</td>\n",
       "      <td>-0.008288</td>\n",
       "      <td>-0.008883</td>\n",
       "      <td>-0.007196</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>-0.007223</td>\n",
       "      <td>0.008165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13046</th>\n",
       "      <td>-0.689724</td>\n",
       "      <td>0.270339</td>\n",
       "      <td>-0.320044</td>\n",
       "      <td>0.261136</td>\n",
       "      <td>-0.002876</td>\n",
       "      <td>-1.259431</td>\n",
       "      <td>0.216002</td>\n",
       "      <td>1.008751</td>\n",
       "      <td>-0.477269</td>\n",
       "      <td>0.005765</td>\n",
       "      <td>...</td>\n",
       "      <td>0.484293</td>\n",
       "      <td>0.657897</td>\n",
       "      <td>0.106884</td>\n",
       "      <td>0.249119</td>\n",
       "      <td>1.301834</td>\n",
       "      <td>0.359773</td>\n",
       "      <td>0.435488</td>\n",
       "      <td>-0.426840</td>\n",
       "      <td>-0.326925</td>\n",
       "      <td>-0.675156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13047 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6   \\\n",
       "0     -0.332504  0.172245 -0.116238  0.094762 -0.049907 -0.788415  0.094166   \n",
       "1     -0.589436  0.263487 -0.232126  0.173135 -0.038550 -1.217594  0.178163   \n",
       "2     -0.345709  0.153301 -0.141187  0.119342 -0.083962 -0.749887  0.090132   \n",
       "3     -0.432365  0.194523 -0.215070  0.132175 -0.079571 -0.929174  0.111993   \n",
       "4     -0.279774  0.139654 -0.120850  0.089880 -0.102853 -0.678232  0.051077   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13042 -0.006089  0.004384  0.008655  0.009733  0.002660 -0.008338 -0.007564   \n",
       "13043 -0.523359  0.305356 -0.149150  0.089477  0.042632 -1.293895  0.192093   \n",
       "13044 -0.689724  0.270339 -0.320044  0.261136 -0.002876 -1.259431  0.216002   \n",
       "13045  0.007902  0.001804 -0.001760  0.008787  0.006511 -0.007556  0.006201   \n",
       "13046 -0.689724  0.270339 -0.320044  0.261136 -0.002876 -1.259431  0.216002   \n",
       "\n",
       "             7         8         9   ...        90        91        92  \\\n",
       "0      0.636442 -0.264668 -0.075670  ...  0.386844  0.352235  0.041700   \n",
       "1      0.976128 -0.433724 -0.089417  ...  0.555034  0.582209  0.080897   \n",
       "2      0.594755 -0.260055 -0.034043  ...  0.347890  0.355982  0.014971   \n",
       "3      0.738147 -0.323012 -0.022582  ...  0.390612  0.463735  0.034536   \n",
       "4      0.522569 -0.222429 -0.037328  ...  0.314768  0.314552  0.003595   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "13042 -0.002700 -0.000516 -0.008517  ...  0.009356 -0.004861  0.008112   \n",
       "13043  1.063071 -0.363038 -0.233954  ...  0.607264  0.589680  0.125108   \n",
       "13044  1.008751 -0.477269  0.005765  ...  0.484293  0.657897  0.106884   \n",
       "13045 -0.008532 -0.004208  0.001095  ... -0.008522  0.005386  0.007392   \n",
       "13046  1.008751 -0.477269  0.005765  ...  0.484293  0.657897  0.106884   \n",
       "\n",
       "             93        94        95        96        97        98        99  \n",
       "0      0.145713  0.755200  0.211378  0.181323 -0.343293 -0.139336 -0.316692  \n",
       "1      0.221712  1.192142  0.329190  0.339222 -0.478558 -0.244708 -0.572417  \n",
       "2      0.158488  0.716392  0.183754  0.217741 -0.293098 -0.167957 -0.323338  \n",
       "3      0.160252  0.880091  0.239239  0.249958 -0.348369 -0.183390 -0.427813  \n",
       "4      0.139178  0.617549  0.164465  0.165511 -0.268333 -0.132418 -0.258280  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "13042  0.009054 -0.008368 -0.002677 -0.008360 -0.008883 -0.008379 -0.001913  \n",
       "13043  0.160800  1.162051  0.376272  0.150795 -0.588625 -0.130647 -0.488587  \n",
       "13044  0.249119  1.301834  0.359773  0.435488 -0.426840 -0.326925 -0.675156  \n",
       "13045 -0.000901 -0.008288 -0.008883 -0.007196  0.006209 -0.007223  0.008165  \n",
       "13046  0.249119  1.301834  0.359773  0.435488 -0.426840 -0.326925 -0.675156  \n",
       "\n",
       "[13047 rows x 100 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = clean_df['text_akhir'].apply(lambda x: x.split())\n",
    "\n",
    "w2v_model = Word2Vec(sentences=X2, vector_size=100, window=5, min_count=2, workers=4)\n",
    "\n",
    "def document_vector(w2v_model, doc):\n",
    "    \"\"\"Create document vectors by averaging the word vectors in the document\"\"\"\n",
    "    doc = [word for word in doc if word in w2v_model.wv]\n",
    "    if len(doc) == 0:\n",
    "        return np.zeros(w2v_model.vector_size)\n",
    "    return np.mean([w2v_model.wv[word] for word in doc], axis=0)\n",
    "\n",
    "X_w2v = np.array([document_vector(w2v_model, doc) for doc in X2])\n",
    "\n",
    "w2v_df = pd.DataFrame(X_w2v)\n",
    "\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 80/20\n",
    "tfidf_X_train1, tfidf_X_test1, tfidf_y_train1, tfidf_y_test1 = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Word2Vec 80/20\n",
    "w2v_X_train, w2v_X_test, w2v_y_train, w2v_y_test = train_test_split(X_w2v, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# TF-IDF 70/30\n",
    "tfidf_X_train2, tfidf_X_test2, tfidf_y_train2, tfidf_y_test2 = train_test_split(X_tfidf, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest | TF-IDF | 70/30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - TF-IDF 70/30\n",
      "Accuracy Train: 99.93%\n",
      "Accuracy Test: 91.34%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.88      0.93      0.91      1309\n",
      "     neutral       0.91      0.97      0.94      1266\n",
      "    positive       0.95      0.84      0.89      1340\n",
      "\n",
      "    accuracy                           0.91      3915\n",
      "   macro avg       0.92      0.91      0.91      3915\n",
      "weighted avg       0.92      0.91      0.91      3915\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_tfidf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_tfidf.fit(tfidf_X_train2, tfidf_y_train2)\n",
    "\n",
    "y_pred_train_rf = random_forest_tfidf.predict(tfidf_X_train2)\n",
    "accuracy_train_rf = accuracy_score(tfidf_y_train2, y_pred_train_rf)\n",
    "\n",
    "y_pred_test_rf = random_forest_tfidf.predict(tfidf_X_test2)\n",
    "accuracy_test_rf = accuracy_score(tfidf_y_test2, y_pred_test_rf)\n",
    "\n",
    "print('Random Forest - TF-IDF 70/30')\n",
    "print(f'Accuracy Train: {accuracy_train_rf * 100:.2f}%')\n",
    "print(f'Accuracy Test: {accuracy_test_rf * 100:.2f}%')\n",
    "print(classification_report(tfidf_y_test2, y_pred_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest |  Word2Vec | 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Word2Vec 80/20\n",
      "Accuracy Train: 99.98%\n",
      "Accuracy Test: 87.09%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.89      0.84       845\n",
      "     neutral       0.95      0.96      0.95       876\n",
      "    positive       0.87      0.76      0.81       889\n",
      "\n",
      "    accuracy                           0.87      2610\n",
      "   macro avg       0.87      0.87      0.87      2610\n",
      "weighted avg       0.87      0.87      0.87      2610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "random_forest_w2v = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "random_forest_w2v.fit(w2v_X_train, w2v_y_train)\n",
    "\n",
    "y_pred_train_rf = random_forest_w2v.predict(w2v_X_train)\n",
    "accuracy_train_rf = accuracy_score(w2v_y_train, y_pred_train_rf)\n",
    "\n",
    "y_pred_test_rf = random_forest_w2v.predict(w2v_X_test)\n",
    "accuracy_test_rf = accuracy_score(w2v_y_test, y_pred_test_rf)\n",
    "\n",
    "print('Random Forest - Word2Vec 80/20')\n",
    "print(f'Accuracy Train: {accuracy_train_rf * 100:.2f}%')\n",
    "print(f'Accuracy Test: {accuracy_test_rf * 100:.2f}%')\n",
    "print(classification_report(w2v_y_test, y_pred_test_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM | TF-IDF | 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Machine - TF-IDF 80/20\n",
      "Accuracy Train: 96.89%\n",
      "Accuracy Test: 92.15%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.92      0.94      0.93       845\n",
      "     neutral       0.91      0.95      0.93       876\n",
      "    positive       0.94      0.88      0.91       889\n",
      "\n",
      "    accuracy                           0.92      2610\n",
      "   macro avg       0.92      0.92      0.92      2610\n",
      "weighted avg       0.92      0.92      0.92      2610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(tfidf_X_train1, tfidf_y_train1)\n",
    "\n",
    "y_pred_train_svm = svm_model.predict(tfidf_X_train1)\n",
    "accuracy_train_svm = accuracy_score(tfidf_y_train1, y_pred_train_svm)\n",
    "\n",
    "y_pred_test_svm = svm_model.predict(tfidf_X_test1)\n",
    "accuracy_test_svm = accuracy_score(tfidf_y_test1, y_pred_test_svm)\n",
    "\n",
    "print('Support Vector Machine - TF-IDF 80/20')\n",
    "print(f'Accuracy Train: {accuracy_train_svm * 100:.2f}%')\n",
    "print(f'Accuracy Test: {accuracy_test_svm * 100:.2f}%')\n",
    "print(classification_report(tfidf_y_test1, y_pred_test_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM TF-IDF\n",
    "def predict_svm(text):\n",
    "    cleaned = cleaningText(text)\n",
    "    cleaned = casefoldingText(cleaned)\n",
    "    cleaned = fix_slangwords(cleaned)\n",
    "    tokens = tokenizingText(cleaned)\n",
    "    filtered = filteringText(tokens)\n",
    "    final_text = toSentence(filtered)\n",
    "    vector = tfidf.transform([final_text])\n",
    "    prediction = svm_model.predict(vector)\n",
    "    return prediction[0]\n",
    "\n",
    "# RF TF-IDF\n",
    "def predict_rf_tfidf(text):\n",
    "    cleaned = cleaningText(text)\n",
    "    cleaned = casefoldingText(cleaned)\n",
    "    cleaned = fix_slangwords(cleaned)\n",
    "    tokens = tokenizingText(cleaned)\n",
    "    filtered = filteringText(tokens)\n",
    "    final_text = toSentence(filtered)\n",
    "    vector = tfidf.transform([final_text])\n",
    "    prediction = random_forest_tfidf.predict(vector)\n",
    "    return prediction[0]\n",
    "\n",
    "# RF Word2Vec\n",
    "def predict_rf_word2vec(text):\n",
    "    cleaned = cleaningText(text)\n",
    "    cleaned = casefoldingText(cleaned)\n",
    "    cleaned = fix_slangwords(cleaned)\n",
    "    tokens = tokenizingText(cleaned)\n",
    "    filtered = filteringText(tokens)\n",
    "    final_text = toSentence(filtered)\n",
    "    tokens = final_text.split()\n",
    "    vector = document_vector(w2v_model, tokens).reshape(1, -1)\n",
    "    prediction = random_forest_w2v.predict(vector)\n",
    "    return prediction[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Prediction: positive\n",
      "Random Forest Prediction (TF-IDF): positive\n",
      "Random Forest Prediction (Word2Vec): positive\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Sangat dimudahkan dengan adanya aplikasi Caranya mudah dan cepat\"\n",
    "\n",
    "# SVM TF-IDF\n",
    "svm_prediction = predict_svm(sample_text)\n",
    "print(f\"SVM Prediction: {svm_prediction}\")\n",
    "\n",
    "# Random Forest TF-IDF\n",
    "rf_tfidf_prediction = predict_rf_tfidf(sample_text)\n",
    "print(f\"Random Forest Prediction (TF-IDF): {rf_tfidf_prediction}\")\n",
    "\n",
    "# Random Forest Word2Vec\n",
    "rf_word2vec_prediction = predict_rf_word2vec(sample_text)\n",
    "print(f\"Random Forest Prediction (Word2Vec): {rf_word2vec_prediction}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentimen-analisis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
